{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8DvVp7AAAeD-"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5GdNxeGbbY+GISc5ievAc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwelland/ENGPYHS_3NM4/blob/main/Linear_systems_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goals\n",
        "- Describe the computational complexity of algorithms\n",
        "- Formalize how we solve linear systems\n",
        "- Show how to transform general linear systems into simpler triangular systems with Gauss Elimination\n",
        "- Introduce LU decomposition"
      ],
      "metadata": {
        "id": "njzEoGIZaeAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computational complexity\n",
        "The *computational complexity* of an algorithm characterizes the number of operations it requires (thus comparing the algorithm instead of the hardware). Linear algebra algorithms are characterized in terms of the dimension of their arguments. Complexity is represented in big O notation (similar to the accuracy of function approximations). I.e.: Only the leading order is kept, and constants disregarded.\n",
        "\n"
      ],
      "metadata": {
        "id": "YWl1eF9gGfps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example\n",
        "Traditional matrix multiplication of two $n \\times n$ matricies - involves $n^3$ operations and is thus $O(n^3)$\n",
        "\n",
        "NB: This is algorithm-dependant - The Strassen algorithm has $O^{2.81}$"
      ],
      "metadata": {
        "id": "kNnkXY9_IT85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some complexities of common linear algebra operations:\n",
        "\n",
        "| Operation | Description | Complexity |\n",
        "|---|---|---|\n",
        "| Matrix addition | Adding two matrices of the same size | O(n²) |\n",
        "| Matrix multiplication | Multiplying two matrices | O(n³) (standard algorithm) |\n",
        "| Matrix-vector multiplication | Multiplying a matrix by a vector | O(n²) |\n",
        "| Matrix inversion | Finding the inverse of a matrix | O(n³) |\n",
        "| Determinant calculation | Computing the determinant of a matrix | O(n³) |\n",
        "| Transpose | Swapping rows and columns of a matrix | O(n²) |"
      ],
      "metadata": {
        "id": "qf_2lHRXKn3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High-performance computing introduces a new element to complexity which deals with how algorithms parallelize. This is called *scaling* and measured in $O(number \\ of \\ nodes)$. The goal is usually $O(n)$ but is hard to achieve!"
      ],
      "metadata": {
        "id": "7Rsw2EUkQ_YS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Algorithms for solving linear systems"
      ],
      "metadata": {
        "id": "8DvVp7AAAeD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gauss elimination is an algorithm for the most familiar / intuitive solution technique. Let's reexamine our analytical (symbolic) solution to the previous problem and then make it into a numerical algorithm."
      ],
      "metadata": {
        "id": "YubyaVXHAmnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question:\n",
        "You are organizing a fundraising event and need to buy chairs and tables. Chairs cost \\$20 each and tables cost \\$50 each. You have a budget of \\$700 and need a total of 20 pieces of furniture (chairs and tables combined). How many chairs and tables should you buy?"
      ],
      "metadata": {
        "id": "yWyxdki_BPUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Symbolic manipulation\n",
        "\n",
        "Let $c$ and $t$ be the number of chairs and tables respectively.\n",
        "\n",
        "The budget and pieces equations are,\n",
        "\n",
        "(1) $20 c + 50 t = 700$\n",
        "\n",
        "(2) $  c+t = 20$"
      ],
      "metadata": {
        "id": "48_mK3wxBVyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solve (2) for $c$:\n",
        "\n",
        "$c = 20-t$\n",
        "\n",
        "Substitute into (1):\n",
        "\n",
        "$20 [20-t] + 50t = 700$\n",
        "\n",
        "$t = 10$\n",
        "\n",
        "and substitute into (2) or (1) to find $c$.\n",
        "\n",
        "This works because our first step carries the unkown *symbol* $t$."
      ],
      "metadata": {
        "id": "JnpMRYBtBeTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numerical approach\n",
        "\n",
        "Lets repeat this without carrying symbols.\n",
        "\n",
        "(1) $20 c + 50 t = 700$\n",
        "\n",
        "(2) $  c+t = 20$\n",
        "\n",
        "Multiply (2) by $20$:\n",
        "\n",
        "$20 c + 20 t = 400$\n",
        "\n",
        "and subtract from (1):\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "20 c + &50 t  &=& 700 \\\\\n",
        "-20 c - &20 t &=& -400 \\\\\n",
        "\\hline\n",
        " &30 t &=& 300\n",
        "\\end{eqnarray*}\n",
        "\n",
        "Thus we have simplified the last line until it reaches a trival solution for $t$. Now it is a matter of *substitution* to solve for $c$.\n"
      ],
      "metadata": {
        "id": "qFAu4hCXCera"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: the linear system has been changed (without changing the answer) to:\n",
        "\n",
        "$\\begin{pmatrix}\n",
        "20 & 50 \\\\\n",
        "0 & 30\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "c \\\\\n",
        "t\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "700 \\\\\n",
        "300\n",
        "\\end{pmatrix}$\n",
        "\n",
        "In particular, $A$ is *upper triangular*, from which the answer is easily obtained through *backward substitution*."
      ],
      "metadata": {
        "id": "FAM19Bp_ZVAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Upper triangular matricies\n",
        "\n",
        "An upper triangular matrix, $U$, is a matrix whose elements below the diagonal are zero:\n",
        "\n",
        "$$\\begin{bmatrix}\n",
        "u_{1,1} & u_{1,2} & u_{1,3} & u_{1,4}\\\\\n",
        "0 & u_{2,2}' & u_{2,3}' & u_{2,4}'\\\\\n",
        "0 & 0 & u_{3,3}' & u_{3,4}' \\\\\n",
        "0 & 0 & 0 & u_{4,4}'\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "This is useful because, in equation form,\n",
        "\n",
        "$U x = b'$\n",
        "\n",
        "turns in to\n",
        "\\begin{eqnarray*}\n",
        "\\begin{array}{}\n",
        " u_{1,1} x_1 &+& u_{1,2} x_2 & + & u_{1,3} x_{3} &+&u_{1,4} x_4 &=& b'_1,\\\\\n",
        "& & u_{2,2}' x_{2} &+ & u_{2,3}' x_{3} &+& u_{2,4}' x_4 &=& b_{2}' \\\\\n",
        "&& & & u_{3,3}' x_{3} &+& u_{3,4}' x_4 &=& b_{3}',\\\\\n",
        "&& && && u_{4,4}' x_4 &=& b_{4}'.\n",
        "\\end{array}\n",
        "\\end{eqnarray*}"
      ],
      "metadata": {
        "id": "v4GBuvT0slw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gauss Elimination\n",
        "\n",
        "Gauss Elimination proceeds in two phases. The first is elimination which transforms\n",
        "\n",
        "$A x = b$\n",
        "\n",
        "into\n",
        "\n",
        "$U x = b'$\n",
        "\n",
        "where $U$ is an upper triangular matrix and $b'$ is a modified vector of constants. The second phase is back-substitution which is trivial with triangular matricies."
      ],
      "metadata": {
        "id": "g_WY_oMAZsQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gauss elimination algorithm\n",
        "\n",
        "We first take\n",
        "\n",
        "$Ax = b$\n",
        "\n",
        "and build an *Augmented matrix*:\n",
        "\n",
        "$Ab = [ A | b ]$\n",
        "\n",
        " We are allowed the following operations which affect $|A|$ but not the solution to the problem:\n",
        "\n",
        "|Operation | Effect on $|A|$ |\n",
        "|-----|-----|\n",
        "|Exchange 2 rows | Flips sign|\n",
        "|Multiply a row by § | Multiplied by § |\n",
        "|Subtract 2 rows     | Unchanged|"
      ],
      "metadata": {
        "id": "UYC-PAVaDwqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Steps from our previous example"
      ],
      "metadata": {
        "id": "qfMYLZ_pbkdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Define A and b\n",
        "\n",
        "A = np.array([[20, 50],\n",
        "              [1, 1]])\n",
        "\n",
        "b = np.array([[700], [20]])\n",
        "\n",
        "#Form the augmented matrix A|b\n",
        "Ab = np.hstack([A, b])\n",
        "\n",
        "#The coefficient matrix can be separated by slicing Ab\n",
        "def print_update():\n",
        "  print(\"Augmented matrix is \\n\", Ab)\n",
        "  print(\"Determinant of A: \", np.linalg.det(Ab[:,:-1])),\n",
        "  print(\"Norm of A\", np.linalg.norm(Ab[:,:-1], 'fro')),\n",
        "  print(\"Condition number of A:\", np.linalg.cond(Ab[:, :-1]))\n",
        "  print(\"\\n\")\n",
        "\n",
        "print(\"Step 0: Show the augmented matrix and the determinant of A\")\n",
        "print_update()\n",
        "\n",
        "print(\"Step 1: Multiply the second row by 20\")\n",
        "Ab[1, :] = Ab[1, :] * 20\n",
        "print_update()\n",
        "\n",
        "print(\"Step 2: Subtract the second row from the first\")\n",
        "Ab[1, :] = Ab[1, :] - Ab[0, :]\n",
        "print_update()"
      ],
      "metadata": {
        "id": "vgi4vBeXF1_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The determinant, norm and condition number are all changing despite the answer remaining the same. This is the basis of preconditioners!"
      ],
      "metadata": {
        "id": "RWIEeTtqvdNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm\n",
        "\n"
      ],
      "metadata": {
        "id": "CGcRybA6bg3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's describe an algorithm for Gaussian elimination, as a sequence of passes row by row through the matrix.\n",
        "\n",
        "Each pass we choose a *pivot row* which is used to eliminate the elements in other equations through multiplication of the pivot and subtraction.\n",
        "\n",
        "Start from the top and only pass downwards, so we end up with an upper triangular matrix."
      ],
      "metadata": {
        "id": "rtzcmy2HxUba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Example\n",
        "\n",
        "Use Gauss Elimination to solve the following equations.\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "4x_1 + 3x_2 - 5x_3 &=& 2 \\\\\n",
        "-2x_1 - 4x_2 + 5x_3 &=& 5 \\\\\n",
        "8x_1 + 8x_2  &=& -3 \\\\\n",
        "\\end{eqnarray*}"
      ],
      "metadata": {
        "id": "aWBYESevcq9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Turn these equations to matrix form $Ax=y$.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & 3 & -5\\\\\n",
        "-2 & -4 & 5\\\\\n",
        "8 & 8 & 0\\\\\n",
        "\\end{bmatrix}\\left[\\begin{array}{c} x_1 \\\\x_2 \\\\x_3 \\end{array}\\right] =\n",
        "\\left[\\begin{array}{c} 2 \\\\5 \\\\-3\\end{array}\\right]$$"
      ],
      "metadata": {
        "id": "V4MRmE2Bcw-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Get the augmented matrix [A, y]\n",
        "\n",
        "$$\n",
        "[A, y]  = \\begin{bmatrix}\n",
        "4 & 3 & -5 & 2\\\\\n",
        "-2 & -4 & 5 & 5\\\\\n",
        "8 & 8 & 0 & -3\\\\\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "-j_g6SSOc0M8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Choose the first equation as the pivot equation and turn the 2nd row first element to 0. To do this, we can multiply -0.5 for the 1st row (pivot equation) and subtract it from the 2nd row. The multiplier is $m_{2,1}=-0.5$. We will get\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & 3 & -5 & 2\\\\\n",
        "0 & -2.5 & 2.5 & 6\\\\\n",
        "8 & 8 & 0 & -3\\\\\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "6j6iWcr0c1DD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Turn the 3rd row first element to 0. We can do something similar, multiply 2 to the 1st row and subtract it from the 3rd row. The multiplier is $m_{3,1}=2$. We will get\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & 3 & -5 & 2\\\\\n",
        "0 & -2.5 & 2.5 & 6\\\\\n",
        "0 & 2 & 10 & -7\\\\\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "ZuQHvY0Gc5Cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Turn the 3rd row 2nd element to 0. We can multiple -4/5 for the 2nd row, and subtract it from the 3rd row. The multiplier is $m_{3,2}=-0.8$. We will get\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & 3 & -5 & 2\\\\\n",
        "0 & -2.5 & 2.5 & 6\\\\\n",
        "0 & 0 & 12 & -2.2\\\\\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "g9ALF2Zpc9Uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elmination is now complete since $A$ is upper triangular.\n",
        "\n",
        "Proceed with substitution:\n",
        "\n",
        "Step 6: Therefore, we can get $x_3=-2.2/12=-0.183$.\n",
        "\n",
        "Step 7: Insert $x_3$ to the 2nd equation, we get $x_2=-2.583$\n",
        "\n",
        "Step 8: Insert $x_2$ and $x_3$ to the first equation, we have $x_1=2.208$."
      ],
      "metadata": {
        "id": "dmEMlmYRc_wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complexity\n",
        "\n",
        "Considering the two phases of Gauss elimination:\n",
        "\n",
        "Elimination: ~$n^3/3$ operations, therefore, $O(n^3)$\n",
        "\n",
        "Back substitution: $O(n^2/2)$\n"
      ],
      "metadata": {
        "id": "XxXtEjqzLxJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gauss-Jordan Elimination\n",
        "An obvious extension is to conduct each pass both upwards and downwards (G.E. is just down). While doing this we also normalize the row to get reduced row echelon form:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 & 2.208\\\\\n",
        "0 & 1 & 0 & -2.583\\\\\n",
        "0 & 0 & 1 & -0.183\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Since $I^{-1} = I$, the answer is just the right hand vector."
      ],
      "metadata": {
        "id": "g1T61zk3uHjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complexity\n",
        "Gauss-Jordan Elimination eliminates the need for back-substitution so one might think that it is more efficient than Gauss Elimination. Unfortunatley, the elimination phase takes ~$~n^3/2$ operations whereas GE took ~$n^3/3 + n^2/2$. therefore Gauss Elimination is preferred."
      ],
      "metadata": {
        "id": "M1g9YM2tMbwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pivoting and diagonal dominance\n",
        "\n"
      ],
      "metadata": {
        "id": "FzKC2Byc0mrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The order of equations, and therefore rows in the matrix, is obviously arbitrary, but this may break Gauss Elimination.\n",
        "\n",
        "E.g.: a system with augmented matrix\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "2 & -1 & 0 & 1\\\\\n",
        "-1 & 2 & -1 & 0\\\\\n",
        "0 & -1 & 1 & 0\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "will work with our GE scheme, but the same system reordered,\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "0 & -1 & 1 & 0\\\\\n",
        "-1 & 2 & -1 & 0\\\\\n",
        "2 & -1 & 0 & 1\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "will fail due to the $0$ in the element of the first row."
      ],
      "metadata": {
        "id": "877cpzFQ1kM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More generally, if the diagonal element is *small* we will encounter roundoff error:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "\\epsilon & -1 & 1 & 0\\\\\n",
        "-1 & 2 & -1 & 0\\\\\n",
        "2 & -1 & 0 & 1\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "after the first pass leads to:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "\\epsilon & -1 & 1 & 0\\\\\n",
        "-1 & 2 -1/\\epsilon & -1 + 1/\\epsilon & 0\\\\\n",
        "2 & -1 -1/\\epsilon& + 1/\\epsilon & 1\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "from which we immediately see the danger as $\\epsilon \\rightarrow 0$!"
      ],
      "metadata": {
        "id": "-MTl4rcz32Ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus it may be important to swap rows in order to have GE succeed. In particular you don't want the diagonal to have $0$s or *small* numbers...\n"
      ],
      "metadata": {
        "id": "zIophKsK4rJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Diagonal dominance\n",
        "\n",
        "A matrix is said to be *diagonally dominant* if each diagonal is larger, in absolute value, than the *sum of the other elements in the row*.\n",
        "\n",
        "$|A_{ii}| \\ge \\sum_{j=1,j \\ne i}^{n} |A_{ij}|$\n"
      ],
      "metadata": {
        "id": "wVzt8kXh4pAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: Which is diagonally dominant?\n",
        "\n",
        "a) $$\n",
        "\\begin{bmatrix}\n",
        "-2 & 4 & -1 \\\\\n",
        "-1 & -1 & 3 \\\\\n",
        "4 & -2 & 1 \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "b)\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & -2 & 1 \\\\\n",
        "-2 & 4 & -1 \\\\\n",
        "-1 & -1 & 3 \\\\\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "g4Vv_A3858SK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importance of diagonal dominance\n",
        "It can be shown that if a matrix is diagonally dominant, *it will not benefit from pivoting!*.\n",
        "\n",
        "As a side benefit, it precludes singular matricies.  \n",
        "\n",
        "Diagonal dominance contributes generaelly to numerical stability and accuracy through minimizing roundoff error propogation. This result extends beyond Gauss elimination, and will also be a criteria for matrix factorization methods and the efficient convergence of iterative methods."
      ],
      "metadata": {
        "id": "kcVtBeJ67o8Y"
      }
    }
  ]
}